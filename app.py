import streamlit as st
import google.generativeai as genai
from gtts import gTTS
import PyPDF2
import io
import re

# === ğŸ¨ ç”»é¢ãƒ‡ã‚¶ã‚¤ãƒ³ã®ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºï¼ˆCSSï¼‰ ===
st.markdown("""
    <style>
    [data-testid="stAudioInput"] {
        border: 3px solid #FF4B4B;
        border-radius: 15px;
        padding: 10px;
        background-color: #FFF5F5;
        margin-bottom: 20px;
    }
    .mic-guide {
        font-size: 1.2rem;
        font-weight: bold;
        color: #FF4B4B;
        text-align: center;
        margin-bottom: 5px;
    }
    </style>
    """, unsafe_allow_html=True)

# === ğŸšª å…¥å ´ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ ===
APP_PASSWORD = st.secrets.get("APP_PASSWORD", "1234")
if "password_correct" not in st.session_state:
    st.session_state["password_correct"] = False
if not st.session_state["password_correct"]:
    st.title("ğŸ”’ å®¶æ—å°‚ç”¨ AIè‹±ä¼šè©±")
    pwd = st.text_input("åˆè¨€è‘‰ï¼ˆãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ï¼‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", type="password")
    if pwd == APP_PASSWORD:
        st.session_state["password_correct"] = True
        st.rerun()
    st.stop() 

# === ğŸ”‘ APIè¨­å®š ===
try:
    genai.configure(api_key=st.secrets["GEMINI_API_KEY"].strip())
except:
    st.error("APIã‚­ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
    st.stop()

# === ğŸ§  çŠ¶æ…‹ã®åˆæœŸåŒ– ===
if "messages" not in st.session_state:
    st.session_state.messages = []
if "last_processed_audio" not in st.session_state:
    st.session_state.last_processed_audio = None
if "last_played_msg_idx" not in st.session_state:
    st.session_state.last_played_msg_idx = -1

st.title("My English Roleplay AI ğŸ—£ï¸")

# === âš™ï¸ ã‚µã‚¤ãƒ‰ãƒãƒ¼ ===
with st.sidebar:
    st.header("âš™ï¸ è¨­å®šãƒ¡ãƒ‹ãƒ¥ãƒ¼")
    model_options = {"Gemini 2.5 Flash (é«˜é€Ÿ)": "gemini-2.5-flash", "Gemini 2.5 Flash-Lite (æœ€é€Ÿ)": "gemini-2.5-flash-lite"}
    selected_model = model_options[st.selectbox("AIãƒ¢ãƒ‡ãƒ«", list(model_options.keys()))]
    level = st.selectbox("ğŸ“ˆ ä¼šè©±ã®ãƒ¬ãƒ™ãƒ«", ["1: è¶…åˆå¿ƒè€…", "2: åˆå¿ƒè€…", "3: ä¸­ç´šè€…", "4: ä¸Šç´šè€…", "5: å°‚é–€å®¶"])
    input_name = st.text_input("ğŸ“› ã‚ãªãŸã®åå‰", "masa")
    user_name = input_name if input_name else "Anata"
    preset_questioner = st.selectbox("AIã®å½¹æŸ„", ["å°å­¦æ ¡ã®å…ˆç”Ÿ", "åŒå¹´ä»£ã®å‹é”", "è·å ´ã®å…ˆè¼©", "æ°—ã•ããªå‹é”", "ãã®ä»–"])
    questioner = st.text_input("å½¹å‰²ã‚’å…¥åŠ›", "ç©ºæ¸¯ã®å…¥å›½å¯©æŸ»å®˜") if preset_questioner == "ãã®ä»–" else preset_questioner
    situation = st.text_area("ğŸ¬ ã‚·ãƒãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³", "ä¾‹: å¥½ããªé£Ÿã¹ç‰©ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„ã€‚", height=100)
    uploaded_file = st.file_uploader("PDF/TXTãƒ•ã‚¡ã‚¤ãƒ«", type=["pdf", "txt"])
    st.markdown("---")
    start_button = st.button("â–¶ï¸ ä¼šè©±ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¦ã‚¹ã‚¿ãƒ¼ãƒˆ", type="primary", use_container_width=True)
    end_button = st.button("ğŸ›‘ ä¼šè©±ã‚’çµ‚äº†ã—ã¦è©•ä¾¡ã‚’ã‚‚ã‚‰ã†", use_container_width=True)

# ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º
def extract_text(file):
    text = ""
    if file.name.endswith('.pdf'):
        reader = PyPDF2.PdfReader(file)
        for page in reader.pages: text += page.extract_text() + "\n"
    elif file.name.endswith('.txt'):
        text = file.read().decode('utf-8')
    return text
doc_text = extract_text(uploaded_file) if uploaded_file else ""

system_instruction = f"ã‚ãªãŸã¯{questioner}ã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼{user_name}ï¼ˆãƒ¬ãƒ™ãƒ«:{level}ï¼‰ã®è‹±ä¼šè©±ç›¸æ‰‹ã§ã™ã€‚ã‚·ãƒãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã¯{situation}ã§ã™ã€‚è³‡æ–™ï¼š{doc_text}ã€‚å¿…ãš [ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯] ã¨ [è‹±èªã®è³ªå•] ã®å½¢å¼ã§ç°¡æ½”ã«ç­”ãˆã¦ãã ã•ã„ã€‚"

# ä¼šè©±ã®åˆæœŸåŒ–
if start_button:
    st.session_state.chat_session = genai.GenerativeModel(selected_model, system_instruction=system_instruction).start_chat(history=[])
    st.session_state.messages = []
    st.session_state.last_played_msg_idx = -1
    st.session_state.last_processed_audio = None # ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªå±¥æ­´ã‚‚ãƒªã‚»ãƒƒãƒˆ
    response = st.session_state.chat_session.send_message("ã‚·ãƒãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚’é–‹å§‹ã—ã¦ã€æœ€åˆã®è³ªå•ã‚’è‹±èªã§ã—ã¦ãã ã•ã„ã€‚")
    st.session_state.messages.append({"role": "assistant", "content": response.text})

# ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸è¡¨ç¤ºã¨èª­ã¿ä¸Šã’
if "chat_session" in st.session_state:
    for i, message in enumerate(st.session_state.messages):
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
            if message["role"] == "assistant" and "[è‹±èªã®è³ªå•]" in message["content"]:
                raw_text = message["content"].split("[è‹±èªã®è³ªå•]")[1].strip()
                clean_english = re.sub(r'\(.*?\)', '', raw_text).strip()
                if clean_english:
                    try:
                        tts = gTTS(text=clean_english, lang='en')
                        fp = io.BytesIO()
                        tts.write_to_fp(fp)
                        fp.seek(0)
                        is_last = (i == len(st.session_state.messages) - 1)
                        if is_last and st.session_state.last_played_msg_idx != i:
                            st.session_state.last_played_msg_idx = i
                            st.audio(fp, format="audio/mp3", autoplay=True)
                        else:
                            st.audio(fp, format="audio/mp3", autoplay=False)
                    except: pass

    st.markdown("---")
    st.markdown('<p class="mic-guide">ğŸ‘‡ éŒ²éŸ³ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦è‹±èªã§è©±ã—ã¦ã­ï¼</p>', unsafe_allow_html=True)
    
    # ğŸ†˜ ã‚®ãƒ–ã‚¢ãƒƒãƒ—ãƒœã‚¿ãƒ³
    if st.button("ğŸ†˜ ã‚®ãƒ–ã‚¢ãƒƒãƒ—ï¼ˆè§£èª¬ã‚’è¦‹ã‚‹ï¼‰"):
        res = st.session_state.chat_session.send_message("ä»Šã®è³ªå•ã®æ„å›³ã€æ—¥æœ¬èªè¨³ã€å›ç­”ä¾‹ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚ãã®å¾Œã€åˆ¥ã®è³ªå•ã‚’è‹±èªã§ã—ã¦ãã ã•ã„ã€‚")
        st.session_state.messages.append({"role": "user", "content": "ï¼ˆğŸ†˜ ã‚®ãƒ–ã‚¢ãƒƒãƒ—ã—ã¾ã—ãŸï¼‰"})
        st.session_state.messages.append({"role": "assistant", "content": res.text})
        st.rerun()

    # ğŸ™ï¸ éŸ³å£°å…¥åŠ›
    audio_value = st.audio_input("éŒ²éŸ³")

    # â˜…ã‚ºãƒ¬é˜²æ­¢ã®æ ¸å¿ƒéƒ¨â˜…
    if audio_value is not None:
        current_audio_data = audio_value.getvalue()
        # ã€Œã¾ã å‡¦ç†ã—ã¦ã„ãªã„æ–°ã—ã„éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã€ãŒã‚ã‚‹å ´åˆã®ã¿å®Ÿè¡Œ
        if st.session_state.last_processed_audio != current_audio_data:
            with st.spinner("AIãŒèãå–ã£ã¦ã„ã¾ã™..."):
                try:
                    # éŸ³å£°ã‚’æ–‡å­—èµ·ã“ã—
                    trans_model = genai.GenerativeModel(selected_model)
                    trans_res = trans_model.generate_content([{"mime_type": "audio/wav", "data": current_audio_data}, "èã“ãˆãŸè‹±èªã‚’ãã®ã¾ã¾æ–‡å­—èµ·ã“ã—ã—ã¦ãã ã•ã„ã€‚"])
                    user_text = trans_res.text.strip()
                    
                    if user_text:
                        # 1. å‡¦ç†æ¸ˆã¿ãƒªã‚¹ãƒˆã«ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ï¼ˆäºŒé‡å‡¦ç†ã‚’é˜²æ­¢ï¼‰
                        st.session_state.last_processed_audio = current_audio_data
                        # 2. ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
                        st.session_state.messages.append({"role": "user", "content": user_text})
                        # 3. AIã«è¿”ç­”ã•ã›ã‚‹
                        ai_res = st.session_state.chat_session.send_message(user_text)
                        st.session_state.messages.append({"role": "assistant", "content": ai_res.text})
                        # 4. å³åº§ã«ãƒªãƒ­ãƒ¼ãƒ‰
                        st.rerun()
                except:
                    st.error("ã†ã¾ãèãå–ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")

    # âŒ¨ï¸ ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›
    with st.expander("âŒ¨ï¸ æ–‡å­—ã§å…¥åŠ›ã—ãŸã„å ´åˆã¯ã“ã¡ã‚‰"):
        with st.form("text_input", clear_on_submit=True):
            t_prompt = st.text_input("è‹±èªã‚’å…¥åŠ›:")
            if st.form_submit_button("é€ä¿¡") and t_prompt:
                st.session_state.messages.append({"role": "user", "content": t_prompt})
                ai_res = st.session_state.chat_session.send_message(t_prompt)
                st.session_state.messages.append({"role": "assistant", "content": ai_res.text})
                st.rerun()
else:
    st.info("ğŸ‘ˆ å·¦å´ã®ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‚’è¨­å®šã—ã€ã‚¹ã‚¿ãƒ¼ãƒˆãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")
